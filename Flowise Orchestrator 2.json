{
  "nodes": [
    {
      "id": "agentAgentflow_0",
      "position": {
        "x": 65.52505742635259,
        "y": -418.2307515150152
      },
      "data": {
        "id": "agentAgentflow_0",
        "label": "Categorize Agent",
        "version": 3.2,
        "name": "agentAgentflow",
        "type": "Agent",
        "color": "#4DD0E1",
        "baseClasses": [
          "Agent"
        ],
        "category": "Agent Flows",
        "description": "Dynamically choose and utilize tools during runtime, enabling multi-step reasoning",
        "inputParams": [
          {
            "label": "Model",
            "name": "agentModel",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "loadConfig": true,
            "id": "agentAgentflow_0-input-agentModel-asyncOptions",
            "display": true
          },
          {
            "label": "Messages",
            "name": "agentMessages",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Role",
                "name": "role",
                "type": "options",
                "options": [
                  {
                    "label": "System",
                    "name": "system"
                  },
                  {
                    "label": "Assistant",
                    "name": "assistant"
                  },
                  {
                    "label": "Developer",
                    "name": "developer"
                  },
                  {
                    "label": "User",
                    "name": "user"
                  }
                ]
              },
              {
                "label": "Content",
                "name": "content",
                "type": "string",
                "acceptVariable": true,
                "generateInstruction": true,
                "rows": 4
              }
            ],
            "id": "agentAgentflow_0-input-agentMessages-array",
            "display": true
          },
          {
            "label": "OpenAI Built-in Tools",
            "name": "agentToolsBuiltInOpenAI",
            "type": "multiOptions",
            "optional": true,
            "options": [
              {
                "label": "Web Search",
                "name": "web_search_preview",
                "description": "Search the web for the latest information"
              },
              {
                "label": "Code Interpreter",
                "name": "code_interpreter",
                "description": "Write and run Python code in a sandboxed environment"
              },
              {
                "label": "Image Generation",
                "name": "image_generation",
                "description": "Generate images based on a text prompt"
              }
            ],
            "show": {
              "agentModel": "chatOpenAI"
            },
            "id": "agentAgentflow_0-input-agentToolsBuiltInOpenAI-multiOptions",
            "display": true
          },
          {
            "label": "Gemini Built-in Tools",
            "name": "agentToolsBuiltInGemini",
            "type": "multiOptions",
            "optional": true,
            "options": [
              {
                "label": "URL Context",
                "name": "urlContext",
                "description": "Extract content from given URLs"
              },
              {
                "label": "Google Search",
                "name": "googleSearch",
                "description": "Search real-time web content"
              },
              {
                "label": "Code Execution",
                "name": "codeExecution",
                "description": "Write and run Python code in a sandboxed environment"
              }
            ],
            "show": {
              "agentModel": "chatGoogleGenerativeAI"
            },
            "id": "agentAgentflow_0-input-agentToolsBuiltInGemini-multiOptions",
            "display": false
          },
          {
            "label": "Anthropic Built-in Tools",
            "name": "agentToolsBuiltInAnthropic",
            "type": "multiOptions",
            "optional": true,
            "options": [
              {
                "label": "Web Search",
                "name": "web_search_20250305",
                "description": "Search the web for the latest information"
              },
              {
                "label": "Web Fetch",
                "name": "web_fetch_20250910",
                "description": "Retrieve full content from specified web pages"
              }
            ],
            "show": {
              "agentModel": "chatAnthropic"
            },
            "id": "agentAgentflow_0-input-agentToolsBuiltInAnthropic-multiOptions",
            "display": false
          },
          {
            "label": "Tools",
            "name": "agentTools",
            "type": "array",
            "optional": true,
            "array": [
              {
                "label": "Tool",
                "name": "agentSelectedTool",
                "type": "asyncOptions",
                "loadMethod": "listTools",
                "loadConfig": true
              },
              {
                "label": "Require Human Input",
                "name": "agentSelectedToolRequiresHumanInput",
                "type": "boolean",
                "optional": true
              }
            ],
            "id": "agentAgentflow_0-input-agentTools-array",
            "display": true
          },
          {
            "label": "Knowledge (Document Stores)",
            "name": "agentKnowledgeDocumentStores",
            "type": "array",
            "description": "Give your agent context about different document sources. Document stores must be upserted in advance.",
            "array": [
              {
                "label": "Document Store",
                "name": "documentStore",
                "type": "asyncOptions",
                "loadMethod": "listStores"
              },
              {
                "label": "Describe Knowledge",
                "name": "docStoreDescription",
                "type": "string",
                "generateDocStoreDescription": true,
                "placeholder": "Describe what the knowledge base is about, this is useful for the AI to know when and how to search for correct information",
                "rows": 4
              },
              {
                "label": "Return Source Documents",
                "name": "returnSourceDocuments",
                "type": "boolean",
                "optional": true
              }
            ],
            "optional": true,
            "id": "agentAgentflow_0-input-agentKnowledgeDocumentStores-array",
            "display": true
          },
          {
            "label": "Knowledge (Vector Embeddings)",
            "name": "agentKnowledgeVSEmbeddings",
            "type": "array",
            "description": "Give your agent context about different document sources from existing vector stores and embeddings",
            "array": [
              {
                "label": "Vector Store",
                "name": "vectorStore",
                "type": "asyncOptions",
                "loadMethod": "listVectorStores",
                "loadConfig": true
              },
              {
                "label": "Embedding Model",
                "name": "embeddingModel",
                "type": "asyncOptions",
                "loadMethod": "listEmbeddings",
                "loadConfig": true
              },
              {
                "label": "Knowledge Name",
                "name": "knowledgeName",
                "type": "string",
                "placeholder": "A short name for the knowledge base, this is useful for the AI to know when and how to search for correct information"
              },
              {
                "label": "Describe Knowledge",
                "name": "knowledgeDescription",
                "type": "string",
                "placeholder": "Describe what the knowledge base is about, this is useful for the AI to know when and how to search for correct information",
                "rows": 4
              },
              {
                "label": "Return Source Documents",
                "name": "returnSourceDocuments",
                "type": "boolean",
                "optional": true
              }
            ],
            "optional": true,
            "id": "agentAgentflow_0-input-agentKnowledgeVSEmbeddings-array",
            "display": true
          },
          {
            "label": "Enable Memory",
            "name": "agentEnableMemory",
            "type": "boolean",
            "description": "Enable memory for the conversation thread",
            "default": true,
            "optional": true,
            "id": "agentAgentflow_0-input-agentEnableMemory-boolean",
            "display": true
          },
          {
            "label": "Memory Type",
            "name": "agentMemoryType",
            "type": "options",
            "options": [
              {
                "label": "All Messages",
                "name": "allMessages",
                "description": "Retrieve all messages from the conversation"
              },
              {
                "label": "Window Size",
                "name": "windowSize",
                "description": "Uses a fixed window size to surface the last N messages"
              },
              {
                "label": "Conversation Summary",
                "name": "conversationSummary",
                "description": "Summarizes the whole conversation"
              },
              {
                "label": "Conversation Summary Buffer",
                "name": "conversationSummaryBuffer",
                "description": "Summarize conversations once token limit is reached. Default to 2000"
              }
            ],
            "optional": true,
            "default": "allMessages",
            "show": {
              "agentEnableMemory": true
            },
            "id": "agentAgentflow_0-input-agentMemoryType-options",
            "display": false
          },
          {
            "label": "Window Size",
            "name": "agentMemoryWindowSize",
            "type": "number",
            "default": "20",
            "description": "Uses a fixed window size to surface the last N messages",
            "show": {
              "agentMemoryType": "windowSize"
            },
            "id": "agentAgentflow_0-input-agentMemoryWindowSize-number",
            "display": false
          },
          {
            "label": "Max Token Limit",
            "name": "agentMemoryMaxTokenLimit",
            "type": "number",
            "default": "2000",
            "description": "Summarize conversations once token limit is reached. Default to 2000",
            "show": {
              "agentMemoryType": "conversationSummaryBuffer"
            },
            "id": "agentAgentflow_0-input-agentMemoryMaxTokenLimit-number",
            "display": false
          },
          {
            "label": "Input Message",
            "name": "agentUserMessage",
            "type": "string",
            "description": "Add an input message as user message at the end of the conversation",
            "rows": 4,
            "optional": true,
            "acceptVariable": true,
            "show": {
              "agentEnableMemory": true
            },
            "id": "agentAgentflow_0-input-agentUserMessage-string",
            "display": false
          },
          {
            "label": "Return Response As",
            "name": "agentReturnResponseAs",
            "type": "options",
            "options": [
              {
                "label": "User Message",
                "name": "userMessage"
              },
              {
                "label": "Assistant Message",
                "name": "assistantMessage"
              }
            ],
            "default": "userMessage",
            "id": "agentAgentflow_0-input-agentReturnResponseAs-options",
            "display": true
          },
          {
            "label": "JSON Structured Output",
            "name": "agentStructuredOutput",
            "description": "Instruct the Agent to give output in a JSON structured schema",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "string"
              },
              {
                "label": "Type",
                "name": "type",
                "type": "options",
                "options": [
                  {
                    "label": "String",
                    "name": "string"
                  },
                  {
                    "label": "String Array",
                    "name": "stringArray"
                  },
                  {
                    "label": "Number",
                    "name": "number"
                  },
                  {
                    "label": "Boolean",
                    "name": "boolean"
                  },
                  {
                    "label": "Enum",
                    "name": "enum"
                  },
                  {
                    "label": "JSON Array",
                    "name": "jsonArray"
                  }
                ]
              },
              {
                "label": "Enum Values",
                "name": "enumValues",
                "type": "string",
                "placeholder": "value1, value2, value3",
                "description": "Enum values. Separated by comma",
                "optional": true,
                "show": {
                  "agentStructuredOutput[$index].type": "enum"
                }
              },
              {
                "label": "JSON Schema",
                "name": "jsonSchema",
                "type": "code",
                "placeholder": "{\n    \"answer\": {\n        \"type\": \"string\",\n        \"description\": \"Value of the answer\"\n    },\n    \"reason\": {\n        \"type\": \"string\",\n        \"description\": \"Reason for the answer\"\n    },\n    \"optional\": {\n        \"type\": \"boolean\"\n    },\n    \"count\": {\n        \"type\": \"number\"\n    },\n    \"children\": {\n        \"type\": \"array\",\n        \"items\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"value\": {\n                    \"type\": \"string\",\n                    \"description\": \"Value of the children's answer\"\n                }\n            }\n        }\n    }\n}",
                "description": "JSON schema for the structured output",
                "optional": true,
                "hideCodeExecute": true,
                "show": {
                  "agentStructuredOutput[$index].type": "jsonArray"
                }
              },
              {
                "label": "Description",
                "name": "description",
                "type": "string",
                "placeholder": "Description of the key"
              }
            ],
            "id": "agentAgentflow_0-input-agentStructuredOutput-array",
            "display": true
          },
          {
            "label": "Update Flow State",
            "name": "agentUpdateState",
            "description": "Update runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "asyncOptions",
                "loadMethod": "listRuntimeStateKeys"
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "acceptVariable": true,
                "acceptNodeOutputAsVariable": true
              }
            ],
            "id": "agentAgentflow_0-input-agentUpdateState-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "agentModel": "chatOpenAI",
          "agentMessages": [
            {
              "role": "system",
              "content": "<p>Categorise the given email content into one of three categories: \"Personal\", \"Meeting Invitation\", or \"Product Update\".</p><p>Please ensure that you analyse the email body provided in the JSON object. Consider the text context and subject of the email to make an informed decision.</p><h1>Steps</h1><ol><li><p>Analyse the content of the email using the following criteria:</p></li></ol><ul><li><p><strong>Personal</strong>: Look for informal language, personal greetings, and content that pertains to personal matters.</p></li><li><p><strong>Meeting Invitation</strong>: Identify keywords or phrases that indicate a scheduling of a meeting, such as \"invite\", \"meeting\", \"schedule\", \"join us\", etc.</p></li><li><p><strong>Product Update</strong>: Look for mentions of products, services, updates, or any promotional language.</p></li></ul><h1>Output Format</h1><p>The output should be in JSON object format, containing the original email input and the assigned category. The structure should look like this:</p><pre><code class=\"language-json\">{\n  \"category\": \"[Assigned Category]\"\n}\n</code></pre><h1>Examples</h1><p><strong>Example 1:</strong></p><ul><li><p><strong>Input:</strong></p></li></ul><pre><code class=\"language-json\">{\n  \"subject\": \"Let's catch up!\",\n  \"Text\": \"Hey! It's been a while. How about we grab coffee?\",\n  \"Sender\": \"Noble Okafor\"\n}\n</code></pre><ul><li><p><strong>Output:</strong></p></li></ul><pre><code class=\"language-json\">{\n  \"category\": \"Personal\"\n}\n</code></pre><p><strong>Example 2:</strong></p><ul><li><p><strong>Input:</strong></p></li></ul><pre><code class=\"language-json\">{\n  \"subject\": \"Meeting Scheduled: Project Update\",\n  \"Text\": \"Dear team, please join us for a meeting tomorrow at 10 AM to discuss the project updates.\",\n  \"Sender\": \"Kira Norman\"\n}\n</code></pre><ul><li><p><strong>Output:</strong></p></li></ul><pre><code class=\"language-json\">{\n  \"category\": \"Meeting Invitation\"\n}\n</code></pre><p>Notes</p><ul><li><p>Ensure to capture the nuances of language when analy<strong>s</strong>ing the email to categorise correctly.</p></li><li><p>Consider edge cases where the email could contain mixed content; prioritise the most relevant category based on context.</p></li></ul>"
            }
          ],
          "agentToolsBuiltInOpenAI": "",
          "agentTools": [],
          "agentKnowledgeDocumentStores": "",
          "agentKnowledgeVSEmbeddings": "",
          "agentEnableMemory": false,
          "agentReturnResponseAs": "assistantMessage",
          "agentStructuredOutput": [],
          "agentUpdateState": "",
          "agentModelConfig": {
            "cache": "",
            "modelName": "gpt-4.1",
            "temperature": "0.9",
            "streaming": false,
            "maxTokens": "",
            "topP": "",
            "frequencyPenalty": "",
            "presencePenalty": "",
            "timeout": "",
            "strictToolCalling": "",
            "stopSequence": "",
            "basepath": "",
            "proxyUrl": "",
            "baseOptions": "",
            "allowImageUploads": false,
            "reasoning": true,
            "agentModel": "chatOpenAI",
            "reasoningEffort": "low",
            "reasoningSummary": "concise"
          },
          "undefined": ""
        },
        "outputAnchors": [
          {
            "id": "agentAgentflow_0-output-agentAgentflow",
            "label": "Agent",
            "name": "agentAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "type": "agentFlow",
      "width": 185,
      "height": 72,
      "selected": false,
      "positionAbsolute": {
        "x": 65.52505742635259,
        "y": -418.2307515150152
      },
      "dragging": false
    },
    {
      "id": "startAgentflow_0",
      "position": {
        "x": -328.1342487803821,
        "y": -416.01598966643314
      },
      "data": {
        "id": "startAgentflow_0",
        "label": "Start",
        "version": 1.1,
        "name": "startAgentflow",
        "type": "Start",
        "color": "#7EE787",
        "hideInput": true,
        "baseClasses": [
          "Start"
        ],
        "category": "Agent Flows",
        "description": "Starting point of the agentflow",
        "inputParams": [
          {
            "label": "Input Type",
            "name": "startInputType",
            "type": "options",
            "options": [
              {
                "label": "Chat Input",
                "name": "chatInput",
                "description": "Start the conversation with chat input"
              },
              {
                "label": "Form Input",
                "name": "formInput",
                "description": "Start the workflow with form inputs"
              }
            ],
            "default": "chatInput",
            "id": "startAgentflow_0-input-startInputType-options",
            "display": true
          },
          {
            "label": "Form Title",
            "name": "formTitle",
            "type": "string",
            "placeholder": "Please Fill Out The Form",
            "show": {
              "startInputType": "formInput"
            },
            "id": "startAgentflow_0-input-formTitle-string",
            "display": false
          },
          {
            "label": "Form Description",
            "name": "formDescription",
            "type": "string",
            "placeholder": "Complete all fields below to continue",
            "show": {
              "startInputType": "formInput"
            },
            "id": "startAgentflow_0-input-formDescription-string",
            "display": false
          },
          {
            "label": "Form Input Types",
            "name": "formInputTypes",
            "description": "Specify the type of form input",
            "type": "array",
            "show": {
              "startInputType": "formInput"
            },
            "array": [
              {
                "label": "Type",
                "name": "type",
                "type": "options",
                "options": [
                  {
                    "label": "String",
                    "name": "string"
                  },
                  {
                    "label": "Number",
                    "name": "number"
                  },
                  {
                    "label": "Boolean",
                    "name": "boolean"
                  },
                  {
                    "label": "Options",
                    "name": "options"
                  }
                ],
                "default": "string"
              },
              {
                "label": "Label",
                "name": "label",
                "type": "string",
                "placeholder": "Label for the input"
              },
              {
                "label": "Variable Name",
                "name": "name",
                "type": "string",
                "placeholder": "Variable name for the input (must be camel case)",
                "description": "Variable name must be camel case. For example: firstName, lastName, etc."
              },
              {
                "label": "Add Options",
                "name": "addOptions",
                "type": "array",
                "show": {
                  "formInputTypes[$index].type": "options"
                },
                "array": [
                  {
                    "label": "Option",
                    "name": "option",
                    "type": "string"
                  }
                ]
              }
            ],
            "id": "startAgentflow_0-input-formInputTypes-array",
            "display": false
          },
          {
            "label": "Ephemeral Memory",
            "name": "startEphemeralMemory",
            "type": "boolean",
            "description": "Start fresh for every execution without past chat history",
            "optional": true,
            "id": "startAgentflow_0-input-startEphemeralMemory-boolean",
            "display": true
          },
          {
            "label": "Flow State",
            "name": "startState",
            "description": "Runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "string",
                "placeholder": "Foo"
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "placeholder": "Bar",
                "optional": true
              }
            ],
            "id": "startAgentflow_0-input-startState-array",
            "display": true
          },
          {
            "label": "Persist State",
            "name": "startPersistState",
            "type": "boolean",
            "description": "Persist the state in the same session",
            "optional": true,
            "id": "startAgentflow_0-input-startPersistState-boolean",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "startInputType": "chatInput",
          "startEphemeralMemory": false,
          "startState": [],
          "startPersistState": ""
        },
        "outputAnchors": [
          {
            "id": "startAgentflow_0-output-startAgentflow",
            "label": "Start",
            "name": "startAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "type": "agentFlow",
      "width": 103,
      "height": 66,
      "selected": false,
      "positionAbsolute": {
        "x": -328.1342487803821,
        "y": -416.01598966643314
      },
      "dragging": false
    },
    {
      "id": "customFunctionAgentflow_0",
      "position": {
        "x": -132.23668205988838,
        "y": -415.9130180717602
      },
      "data": {
        "id": "customFunctionAgentflow_0",
        "label": "Parse JSON",
        "version": 1.1,
        "name": "customFunctionAgentflow",
        "type": "CustomFunction",
        "color": "#E4B7FF",
        "baseClasses": [
          "CustomFunction"
        ],
        "category": "Agent Flows",
        "description": "Execute custom function",
        "inputParams": [
          {
            "label": "Input Variables",
            "name": "customFunctionInputVariables",
            "description": "Input variables can be used in the function with prefix $. For example: $foo",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Variable Name",
                "name": "variableName",
                "type": "string"
              },
              {
                "label": "Variable Value",
                "name": "variableValue",
                "type": "string",
                "acceptVariable": true
              }
            ],
            "id": "customFunctionAgentflow_0-input-customFunctionInputVariables-array",
            "display": true
          },
          {
            "label": "Javascript Function",
            "name": "customFunctionJavascriptFunction",
            "type": "code",
            "codeExample": "/*\n* You can use any libraries imported in Flowise\n* You can use properties specified in Input Variables with the prefix $. For example: $foo\n* You can get default flow config: $flow.sessionId, $flow.chatId, $flow.chatflowId, $flow.input, $flow.state\n* You can get global variables: $vars.<variable-name>\n* Must return a string value at the end of function\n*/\n\nconst fetch = require('node-fetch');\nconst url = 'https://api.open-meteo.com/v1/forecast?latitude=52.52&longitude=13.41&current_weather=true';\nconst options = {\n    method: 'GET',\n    headers: {\n        'Content-Type': 'application/json'\n    }\n};\ntry {\n    const response = await fetch(url, options);\n    const text = await response.text();\n    return text;\n} catch (error) {\n    console.error(error);\n    return '';\n}",
            "description": "The function to execute. Must return a string or an object that can be converted to a string.",
            "id": "customFunctionAgentflow_0-input-customFunctionJavascriptFunction-code",
            "display": true
          },
          {
            "label": "Update Flow State",
            "name": "customFunctionUpdateState",
            "description": "Update runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "asyncOptions",
                "loadMethod": "listRuntimeStateKeys"
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "acceptVariable": true,
                "acceptNodeOutputAsVariable": true
              }
            ],
            "id": "customFunctionAgentflow_0-input-customFunctionUpdateState-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "customFunctionInputVariables": [
            {
              "variableName": "question",
              "variableValue": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"question\" data-label=\"question\">{{ question }}</span> </p>"
            }
          ],
          "customFunctionJavascriptFunction": "let email\ntry {\n  email = JSON.parse($question)\n} catch {\n  throw new Error('Invalid JSON in $question')\n}\n",
          "customFunctionUpdateState": ""
        },
        "outputAnchors": [
          {
            "id": "customFunctionAgentflow_0-output-customFunctionAgentflow",
            "label": "Custom Function",
            "name": "customFunctionAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "type": "agentFlow",
      "width": 150,
      "height": 66,
      "positionAbsolute": {
        "x": -132.23668205988838,
        "y": -415.9130180717602
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "conditionAgentflow_0",
      "position": {
        "x": 296.09560339377094,
        "y": -432.3333869657294
      },
      "data": {
        "id": "conditionAgentflow_0",
        "label": "Assign Summary Format",
        "version": 1,
        "name": "conditionAgentflow",
        "type": "Condition",
        "color": "#FFB938",
        "baseClasses": [
          "Condition"
        ],
        "category": "Agent Flows",
        "description": "Split flows based on If Else conditions",
        "inputParams": [
          {
            "label": "Conditions",
            "name": "conditions",
            "type": "array",
            "description": "Values to compare",
            "acceptVariable": true,
            "default": [
              {
                "type": "string",
                "value1": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"agentAgentflow_0\" data-label=\"agentAgentflow_0\">{{ agentAgentflow_0 }}</span> </p>",
                "operation": "equal",
                "value2": "<p>Personal</p>"
              }
            ],
            "array": [
              {
                "label": "Type",
                "name": "type",
                "type": "options",
                "options": [
                  {
                    "label": "String",
                    "name": "string"
                  },
                  {
                    "label": "Number",
                    "name": "number"
                  },
                  {
                    "label": "Boolean",
                    "name": "boolean"
                  }
                ],
                "default": "string"
              },
              {
                "label": "Value 1",
                "name": "value1",
                "type": "string",
                "default": "",
                "description": "First value to be compared with",
                "acceptVariable": true,
                "show": {
                  "conditions[$index].type": "string"
                }
              },
              {
                "label": "Operation",
                "name": "operation",
                "type": "options",
                "options": [
                  {
                    "label": "Contains",
                    "name": "contains"
                  },
                  {
                    "label": "Ends With",
                    "name": "endsWith"
                  },
                  {
                    "label": "Equal",
                    "name": "equal"
                  },
                  {
                    "label": "Not Contains",
                    "name": "notContains"
                  },
                  {
                    "label": "Not Equal",
                    "name": "notEqual"
                  },
                  {
                    "label": "Regex",
                    "name": "regex"
                  },
                  {
                    "label": "Starts With",
                    "name": "startsWith"
                  },
                  {
                    "label": "Is Empty",
                    "name": "isEmpty"
                  },
                  {
                    "label": "Not Empty",
                    "name": "notEmpty"
                  }
                ],
                "default": "equal",
                "description": "Type of operation",
                "show": {
                  "conditions[$index].type": "string"
                }
              },
              {
                "label": "Value 2",
                "name": "value2",
                "type": "string",
                "default": "",
                "description": "Second value to be compared with",
                "acceptVariable": true,
                "show": {
                  "conditions[$index].type": "string"
                },
                "hide": {
                  "conditions[$index].operation": [
                    "isEmpty",
                    "notEmpty"
                  ]
                }
              },
              {
                "label": "Value 1",
                "name": "value1",
                "type": "number",
                "default": "",
                "description": "First value to be compared with",
                "acceptVariable": true,
                "show": {
                  "conditions[$index].type": "number"
                }
              },
              {
                "label": "Operation",
                "name": "operation",
                "type": "options",
                "options": [
                  {
                    "label": "Smaller",
                    "name": "smaller"
                  },
                  {
                    "label": "Smaller Equal",
                    "name": "smallerEqual"
                  },
                  {
                    "label": "Equal",
                    "name": "equal"
                  },
                  {
                    "label": "Not Equal",
                    "name": "notEqual"
                  },
                  {
                    "label": "Larger",
                    "name": "larger"
                  },
                  {
                    "label": "Larger Equal",
                    "name": "largerEqual"
                  },
                  {
                    "label": "Is Empty",
                    "name": "isEmpty"
                  },
                  {
                    "label": "Not Empty",
                    "name": "notEmpty"
                  }
                ],
                "default": "equal",
                "description": "Type of operation",
                "show": {
                  "conditions[$index].type": "number"
                }
              },
              {
                "label": "Value 2",
                "name": "value2",
                "type": "number",
                "default": 0,
                "description": "Second value to be compared with",
                "acceptVariable": true,
                "show": {
                  "conditions[$index].type": "number"
                }
              },
              {
                "label": "Value 1",
                "name": "value1",
                "type": "boolean",
                "default": false,
                "description": "First value to be compared with",
                "show": {
                  "conditions[$index].type": "boolean"
                }
              },
              {
                "label": "Operation",
                "name": "operation",
                "type": "options",
                "options": [
                  {
                    "label": "Equal",
                    "name": "equal"
                  },
                  {
                    "label": "Not Equal",
                    "name": "notEqual"
                  }
                ],
                "default": "equal",
                "description": "Type of operation",
                "show": {
                  "conditions[$index].type": "boolean"
                }
              },
              {
                "label": "Value 2",
                "name": "value2",
                "type": "boolean",
                "default": false,
                "description": "Second value to be compared with",
                "show": {
                  "conditions[$index].type": "boolean"
                }
              }
            ],
            "id": "conditionAgentflow_0-input-conditions-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "conditions": [
            {
              "type": "string",
              "value1": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"agentAgentflow_0\" data-label=\"agentAgentflow_0\">{{ agentAgentflow_0 }}</span> </p>",
              "operation": "equal",
              "value2": "<p>Personal</p>"
            },
            {
              "type": "string",
              "value1": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"agentAgentflow_0\" data-label=\"agentAgentflow_0\">{{ agentAgentflow_0 }}</span> </p>",
              "operation": "equal",
              "value2": "<p>Meeting Invitation</p>"
            }
          ],
          "undefined": ""
        },
        "outputAnchors": [
          {
            "id": "conditionAgentflow_0-output-0",
            "label": 0,
            "name": 0,
            "description": "Condition 0"
          },
          {
            "id": "conditionAgentflow_0-output-1",
            "label": 1,
            "name": 1,
            "description": "Condition 1"
          },
          {
            "id": "conditionAgentflow_0-output-2",
            "label": 2,
            "name": 2,
            "description": "Else"
          }
        ],
        "outputs": {
          "conditionAgentflow": ""
        },
        "selected": false
      },
      "type": "agentFlow",
      "width": 231,
      "height": 100,
      "positionAbsolute": {
        "x": 296.09560339377094,
        "y": -432.3333869657294
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "llmAgentflow_0",
      "position": {
        "x": 616.8135807796676,
        "y": -547.8627399722618
      },
      "data": {
        "id": "llmAgentflow_0",
        "label": "LLM 0",
        "version": 1.1,
        "name": "llmAgentflow",
        "type": "LLM",
        "color": "#64B5F6",
        "baseClasses": [
          "LLM"
        ],
        "category": "Agent Flows",
        "description": "Large language models to analyze user-provided inputs and generate responses",
        "inputParams": [
          {
            "label": "Model",
            "name": "llmModel",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "loadConfig": true,
            "id": "llmAgentflow_0-input-llmModel-asyncOptions",
            "display": true
          },
          {
            "label": "Messages",
            "name": "llmMessages",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Role",
                "name": "role",
                "type": "options",
                "options": [
                  {
                    "label": "System",
                    "name": "system"
                  },
                  {
                    "label": "Assistant",
                    "name": "assistant"
                  },
                  {
                    "label": "Developer",
                    "name": "developer"
                  },
                  {
                    "label": "User",
                    "name": "user"
                  }
                ]
              },
              {
                "label": "Content",
                "name": "content",
                "type": "string",
                "acceptVariable": true,
                "generateInstruction": true,
                "rows": 4
              }
            ],
            "id": "llmAgentflow_0-input-llmMessages-array",
            "display": true
          },
          {
            "label": "Enable Memory",
            "name": "llmEnableMemory",
            "type": "boolean",
            "description": "Enable memory for the conversation thread",
            "default": true,
            "optional": true,
            "id": "llmAgentflow_0-input-llmEnableMemory-boolean",
            "display": true
          },
          {
            "label": "Memory Type",
            "name": "llmMemoryType",
            "type": "options",
            "options": [
              {
                "label": "All Messages",
                "name": "allMessages",
                "description": "Retrieve all messages from the conversation"
              },
              {
                "label": "Window Size",
                "name": "windowSize",
                "description": "Uses a fixed window size to surface the last N messages"
              },
              {
                "label": "Conversation Summary",
                "name": "conversationSummary",
                "description": "Summarizes the whole conversation"
              },
              {
                "label": "Conversation Summary Buffer",
                "name": "conversationSummaryBuffer",
                "description": "Summarize conversations once token limit is reached. Default to 2000"
              }
            ],
            "optional": true,
            "default": "allMessages",
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_0-input-llmMemoryType-options",
            "display": false
          },
          {
            "label": "Window Size",
            "name": "llmMemoryWindowSize",
            "type": "number",
            "default": "20",
            "description": "Uses a fixed window size to surface the last N messages",
            "show": {
              "llmMemoryType": "windowSize"
            },
            "id": "llmAgentflow_0-input-llmMemoryWindowSize-number",
            "display": false
          },
          {
            "label": "Max Token Limit",
            "name": "llmMemoryMaxTokenLimit",
            "type": "number",
            "default": "2000",
            "description": "Summarize conversations once token limit is reached. Default to 2000",
            "show": {
              "llmMemoryType": "conversationSummaryBuffer"
            },
            "id": "llmAgentflow_0-input-llmMemoryMaxTokenLimit-number",
            "display": false
          },
          {
            "label": "Input Message",
            "name": "llmUserMessage",
            "type": "string",
            "description": "Add an input message as user message at the end of the conversation",
            "rows": 4,
            "optional": true,
            "acceptVariable": true,
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_0-input-llmUserMessage-string",
            "display": false
          },
          {
            "label": "Return Response As",
            "name": "llmReturnResponseAs",
            "type": "options",
            "options": [
              {
                "label": "User Message",
                "name": "userMessage"
              },
              {
                "label": "Assistant Message",
                "name": "assistantMessage"
              }
            ],
            "default": "userMessage",
            "id": "llmAgentflow_0-input-llmReturnResponseAs-options",
            "display": true
          },
          {
            "label": "JSON Structured Output",
            "name": "llmStructuredOutput",
            "description": "Instruct the LLM to give output in a JSON structured schema",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "string"
              },
              {
                "label": "Type",
                "name": "type",
                "type": "options",
                "options": [
                  {
                    "label": "String",
                    "name": "string"
                  },
                  {
                    "label": "String Array",
                    "name": "stringArray"
                  },
                  {
                    "label": "Number",
                    "name": "number"
                  },
                  {
                    "label": "Boolean",
                    "name": "boolean"
                  },
                  {
                    "label": "Enum",
                    "name": "enum"
                  },
                  {
                    "label": "JSON Array",
                    "name": "jsonArray"
                  }
                ]
              },
              {
                "label": "Enum Values",
                "name": "enumValues",
                "type": "string",
                "placeholder": "value1, value2, value3",
                "description": "Enum values. Separated by comma",
                "optional": true,
                "show": {
                  "llmStructuredOutput[$index].type": "enum"
                }
              },
              {
                "label": "JSON Schema",
                "name": "jsonSchema",
                "type": "code",
                "placeholder": "{\n    \"answer\": {\n        \"type\": \"string\",\n        \"description\": \"Value of the answer\"\n    },\n    \"reason\": {\n        \"type\": \"string\",\n        \"description\": \"Reason for the answer\"\n    },\n    \"optional\": {\n        \"type\": \"boolean\"\n    },\n    \"count\": {\n        \"type\": \"number\"\n    },\n    \"children\": {\n        \"type\": \"array\",\n        \"items\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"value\": {\n                    \"type\": \"string\",\n                    \"description\": \"Value of the children's answer\"\n                }\n            }\n        }\n    }\n}",
                "description": "JSON schema for the structured output",
                "optional": true,
                "hideCodeExecute": true,
                "show": {
                  "llmStructuredOutput[$index].type": "jsonArray"
                }
              },
              {
                "label": "Description",
                "name": "description",
                "type": "string",
                "placeholder": "Description of the key"
              }
            ],
            "id": "llmAgentflow_0-input-llmStructuredOutput-array",
            "display": true
          },
          {
            "label": "Update Flow State",
            "name": "llmUpdateState",
            "description": "Update runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "asyncOptions",
                "loadMethod": "listRuntimeStateKeys"
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "acceptVariable": true,
                "acceptNodeOutputAsVariable": true
              }
            ],
            "id": "llmAgentflow_0-input-llmUpdateState-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "llmModel": "chatOpenAI",
          "llmMessages": [
            {
              "role": "system",
              "content": "<p>Write a summary of the email body received in {{question}} in an informal format, if {{conditionAgentflow_0}} equals \"Personal\".</p><h2>Requirements</h2><ul><li><p>Ensure the summary captures the key points of the email.</p></li><li><p>Focus on the essence of the message without excessive jargon or formality.</p></li><li><p>Use the same sentence structure, tone and grammar style as the email. The point is for the summary and the original email to be almost indistinguishable, just the former would be shorter.</p></li><li><p>Make sure you add a \"from sender\" tag at the end of the summary message. Write this in italics</p></li></ul><h1>Steps</h1><ol><li><p>Check if {{conditionAgentflow_0}} is \"Personal\".</p></li><li><p>If it is, read the email body within {{question}}.</p></li><li><p>Identify the main ideas and important details.</p></li><li><p>Rewrite and highlight these points in an informal and conversational style.</p></li><li><p>Ensure clarity and maintain the original intention of the email.</p></li></ol><h1>Output Format</h1><p>The output should be a concise paragraph, approximately 2-4 sentences long, using informal language that reflects a casual conversation style.</p><h1>Examples</h1><p>Input:</p><ul><li><p>{{conditionAgentflow_0}}: \"Personal\"</p></li><li><p>{{question}}: \"Hey, just wanted to check in and see how youve been! Hope work is great, and youre enjoying your new place. Let me know when youre free to catch up!\"</p></li></ul><p>Output: \"Hey! Just checking in. Hope everythings good at work and youre loving the new place! Lets catch up soon! From sender from <span class=\"variable\" data-type=\"mention\" data-id=\"question\" data-label=\"question\">{{ question }}</span> \"</p><p>Input:</p><ul><li><p>{{conditionAgentflow_0}}: \"Work\"</p></li><li><p>{{question}}: \"Please note the changes to the project deadline and ensure all assignments are submitted on time.\"</p></li></ul><p>Output: (No output should be generated since the condition is not met.)</p><h1>Notes</h1><ul><li><p>Be careful to only provide a summary when the specified condition is met.</p></li><li><p>Avoid formality in language; think of how friends talk to each other when summarising.</p></li></ul>"
            }
          ],
          "llmEnableMemory": false,
          "llmReturnResponseAs": "userMessage",
          "llmStructuredOutput": [],
          "llmUpdateState": "",
          "llmModelConfig": {
            "cache": "",
            "modelName": "gpt-4o-mini",
            "temperature": "0.5",
            "streaming": false,
            "maxTokens": "1000",
            "topP": "",
            "frequencyPenalty": "",
            "presencePenalty": "",
            "timeout": "",
            "strictToolCalling": "",
            "stopSequence": "",
            "basepath": "",
            "proxyUrl": "",
            "baseOptions": "",
            "allowImageUploads": "",
            "reasoning": true,
            "llmModel": "chatOpenAI",
            "reasoningEffort": "low",
            "reasoningSummary": "concise"
          }
        },
        "outputAnchors": [
          {
            "id": "llmAgentflow_0-output-llmAgentflow",
            "label": "LLM",
            "name": "llmAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "type": "agentFlow",
      "width": 175,
      "height": 72,
      "selected": false,
      "positionAbsolute": {
        "x": 616.8135807796676,
        "y": -547.8627399722618
      },
      "dragging": false
    },
    {
      "id": "llmAgentflow_1",
      "position": {
        "x": 619.379834607327,
        "y": -418.5309269698298
      },
      "data": {
        "id": "llmAgentflow_1",
        "label": "LLM 0 (1)",
        "version": 1.1,
        "name": "llmAgentflow",
        "type": "LLM",
        "color": "#64B5F6",
        "baseClasses": [
          "LLM"
        ],
        "category": "Agent Flows",
        "description": "Large language models to analyze user-provided inputs and generate responses",
        "inputParams": [
          {
            "label": "Model",
            "name": "llmModel",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "loadConfig": true,
            "id": "llmAgentflow_1-input-llmModel-asyncOptions",
            "display": true
          },
          {
            "label": "Messages",
            "name": "llmMessages",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Role",
                "name": "role",
                "type": "options",
                "options": [
                  {
                    "label": "System",
                    "name": "system"
                  },
                  {
                    "label": "Assistant",
                    "name": "assistant"
                  },
                  {
                    "label": "Developer",
                    "name": "developer"
                  },
                  {
                    "label": "User",
                    "name": "user"
                  }
                ]
              },
              {
                "label": "Content",
                "name": "content",
                "type": "string",
                "acceptVariable": true,
                "generateInstruction": true,
                "rows": 4
              }
            ],
            "id": "llmAgentflow_1-input-llmMessages-array",
            "display": true
          },
          {
            "label": "Enable Memory",
            "name": "llmEnableMemory",
            "type": "boolean",
            "description": "Enable memory for the conversation thread",
            "default": true,
            "optional": true,
            "id": "llmAgentflow_1-input-llmEnableMemory-boolean",
            "display": true
          },
          {
            "label": "Memory Type",
            "name": "llmMemoryType",
            "type": "options",
            "options": [
              {
                "label": "All Messages",
                "name": "allMessages",
                "description": "Retrieve all messages from the conversation"
              },
              {
                "label": "Window Size",
                "name": "windowSize",
                "description": "Uses a fixed window size to surface the last N messages"
              },
              {
                "label": "Conversation Summary",
                "name": "conversationSummary",
                "description": "Summarizes the whole conversation"
              },
              {
                "label": "Conversation Summary Buffer",
                "name": "conversationSummaryBuffer",
                "description": "Summarize conversations once token limit is reached. Default to 2000"
              }
            ],
            "optional": true,
            "default": "allMessages",
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_1-input-llmMemoryType-options",
            "display": false
          },
          {
            "label": "Window Size",
            "name": "llmMemoryWindowSize",
            "type": "number",
            "default": "20",
            "description": "Uses a fixed window size to surface the last N messages",
            "show": {
              "llmMemoryType": "windowSize"
            },
            "id": "llmAgentflow_1-input-llmMemoryWindowSize-number",
            "display": false
          },
          {
            "label": "Max Token Limit",
            "name": "llmMemoryMaxTokenLimit",
            "type": "number",
            "default": "2000",
            "description": "Summarize conversations once token limit is reached. Default to 2000",
            "show": {
              "llmMemoryType": "conversationSummaryBuffer"
            },
            "id": "llmAgentflow_1-input-llmMemoryMaxTokenLimit-number",
            "display": false
          },
          {
            "label": "Input Message",
            "name": "llmUserMessage",
            "type": "string",
            "description": "Add an input message as user message at the end of the conversation",
            "rows": 4,
            "optional": true,
            "acceptVariable": true,
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_1-input-llmUserMessage-string",
            "display": false
          },
          {
            "label": "Return Response As",
            "name": "llmReturnResponseAs",
            "type": "options",
            "options": [
              {
                "label": "User Message",
                "name": "userMessage"
              },
              {
                "label": "Assistant Message",
                "name": "assistantMessage"
              }
            ],
            "default": "userMessage",
            "id": "llmAgentflow_1-input-llmReturnResponseAs-options",
            "display": true
          },
          {
            "label": "JSON Structured Output",
            "name": "llmStructuredOutput",
            "description": "Instruct the LLM to give output in a JSON structured schema",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "string"
              },
              {
                "label": "Type",
                "name": "type",
                "type": "options",
                "options": [
                  {
                    "label": "String",
                    "name": "string"
                  },
                  {
                    "label": "String Array",
                    "name": "stringArray"
                  },
                  {
                    "label": "Number",
                    "name": "number"
                  },
                  {
                    "label": "Boolean",
                    "name": "boolean"
                  },
                  {
                    "label": "Enum",
                    "name": "enum"
                  },
                  {
                    "label": "JSON Array",
                    "name": "jsonArray"
                  }
                ]
              },
              {
                "label": "Enum Values",
                "name": "enumValues",
                "type": "string",
                "placeholder": "value1, value2, value3",
                "description": "Enum values. Separated by comma",
                "optional": true,
                "show": {
                  "llmStructuredOutput[$index].type": "enum"
                }
              },
              {
                "label": "JSON Schema",
                "name": "jsonSchema",
                "type": "code",
                "placeholder": "{\n    \"answer\": {\n        \"type\": \"string\",\n        \"description\": \"Value of the answer\"\n    },\n    \"reason\": {\n        \"type\": \"string\",\n        \"description\": \"Reason for the answer\"\n    },\n    \"optional\": {\n        \"type\": \"boolean\"\n    },\n    \"count\": {\n        \"type\": \"number\"\n    },\n    \"children\": {\n        \"type\": \"array\",\n        \"items\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"value\": {\n                    \"type\": \"string\",\n                    \"description\": \"Value of the children's answer\"\n                }\n            }\n        }\n    }\n}",
                "description": "JSON schema for the structured output",
                "optional": true,
                "hideCodeExecute": true,
                "show": {
                  "llmStructuredOutput[$index].type": "jsonArray"
                }
              },
              {
                "label": "Description",
                "name": "description",
                "type": "string",
                "placeholder": "Description of the key"
              }
            ],
            "id": "llmAgentflow_1-input-llmStructuredOutput-array",
            "display": true
          },
          {
            "label": "Update Flow State",
            "name": "llmUpdateState",
            "description": "Update runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "asyncOptions",
                "loadMethod": "listRuntimeStateKeys"
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "acceptVariable": true,
                "acceptNodeOutputAsVariable": true
              }
            ],
            "id": "llmAgentflow_1-input-llmUpdateState-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "llmModel": "chatOpenAI",
          "llmMessages": [
            {
              "role": "system",
              "content": "<p>If {{conditionAgentflow_0}} equals \"Meeting Invitation\", generate a summary of the email body provided in {{question}}, ensuring the summary is written in a formal tone and formatted to suit a meeting invitation.</p><p>Additional details;<br> The summary should capture the main points of the email body while maintaining a formal, professional language.<br> Focus on clarity and brevity, ensuring that the tone is appropriate for meeting invitations.<br> Do not include personal commentary or additional information that is not reflected in the original email body.</p><h2>Steps</h2><ol><li><p>Verify that the value of {{conditionAgentflow_0}} is \"Meeting Invitation\".</p></li><li><p>Analyse the content of the email body provided in {{question}}.</p></li><li><p>Identify and extract the key points and details from the email that are relevant to a meeting invitation.</p></li><li><p>Write a concise summary in formal language that fits the style of a meeting invitation.</p></li><li><p>Ensure that the output is clear, concise, and adheres to the formal tone expected in meeting invitations.</p></li></ol><h2><strong>Output Format Example</strong></h2><p><br>Input:<br>{{conditionAgentflow_0}}: \"Meeting Invitation\"<br>{{question}}: \"Dear team, I would like to invite you to a project update meeting next Monday at 10 AM in the main conference room. Please prepare your progress reports and any challenges faced during the current phase of the project.</p><p>Output:<br>\" From: {Sender}<br>You have a project update meeting scheduled for next Monday at 10 AM in the main conference room. Kindly prepare and bring your progress reports, along with any challenges encountered during the current project phase. Would you like me to schedule this in your calendar?\"</p><p>Notes<br> Ensure that all reasoning steps are performed before finalising the summary.<br> Do not include any concluding statements or final summaries before the reasoning steps have been executed.<br> Some of such meetings could be Google Meet invitation links or other services. These are also included or considered meeting invitations and should follow the same process.</p>"
            }
          ],
          "llmEnableMemory": false,
          "llmReturnResponseAs": "userMessage",
          "llmStructuredOutput": "",
          "llmUpdateState": "",
          "llmModelConfig": {
            "cache": "",
            "modelName": "o3-mini",
            "temperature": "0.8",
            "streaming": false,
            "maxTokens": "500",
            "topP": "",
            "frequencyPenalty": "",
            "presencePenalty": "",
            "timeout": "",
            "strictToolCalling": "",
            "stopSequence": "",
            "basepath": "",
            "proxyUrl": "",
            "baseOptions": "",
            "allowImageUploads": "",
            "reasoning": true,
            "llmModel": "chatOpenAI",
            "reasoningEffort": "high",
            "reasoningSummary": "concise"
          }
        },
        "outputAnchors": [
          {
            "id": "llmAgentflow_1-output-llmAgentflow",
            "label": "LLM",
            "name": "llmAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "type": "agentFlow",
      "width": 153,
      "height": 72,
      "selected": false,
      "positionAbsolute": {
        "x": 619.379834607327,
        "y": -418.5309269698298
      },
      "dragging": false
    },
    {
      "id": "llmAgentflow_2",
      "position": {
        "x": 636.0334980083603,
        "y": -309.26172566601434
      },
      "data": {
        "id": "llmAgentflow_2",
        "label": "LLM 0 (2)",
        "version": 1.1,
        "name": "llmAgentflow",
        "type": "LLM",
        "color": "#64B5F6",
        "baseClasses": [
          "LLM"
        ],
        "category": "Agent Flows",
        "description": "Large language models to analyze user-provided inputs and generate responses",
        "inputParams": [
          {
            "label": "Model",
            "name": "llmModel",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "loadConfig": true,
            "id": "llmAgentflow_2-input-llmModel-asyncOptions",
            "display": true
          },
          {
            "label": "Messages",
            "name": "llmMessages",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Role",
                "name": "role",
                "type": "options",
                "options": [
                  {
                    "label": "System",
                    "name": "system"
                  },
                  {
                    "label": "Assistant",
                    "name": "assistant"
                  },
                  {
                    "label": "Developer",
                    "name": "developer"
                  },
                  {
                    "label": "User",
                    "name": "user"
                  }
                ]
              },
              {
                "label": "Content",
                "name": "content",
                "type": "string",
                "acceptVariable": true,
                "generateInstruction": true,
                "rows": 4
              }
            ],
            "id": "llmAgentflow_2-input-llmMessages-array",
            "display": true
          },
          {
            "label": "Enable Memory",
            "name": "llmEnableMemory",
            "type": "boolean",
            "description": "Enable memory for the conversation thread",
            "default": true,
            "optional": true,
            "id": "llmAgentflow_2-input-llmEnableMemory-boolean",
            "display": true
          },
          {
            "label": "Memory Type",
            "name": "llmMemoryType",
            "type": "options",
            "options": [
              {
                "label": "All Messages",
                "name": "allMessages",
                "description": "Retrieve all messages from the conversation"
              },
              {
                "label": "Window Size",
                "name": "windowSize",
                "description": "Uses a fixed window size to surface the last N messages"
              },
              {
                "label": "Conversation Summary",
                "name": "conversationSummary",
                "description": "Summarizes the whole conversation"
              },
              {
                "label": "Conversation Summary Buffer",
                "name": "conversationSummaryBuffer",
                "description": "Summarize conversations once token limit is reached. Default to 2000"
              }
            ],
            "optional": true,
            "default": "allMessages",
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_2-input-llmMemoryType-options",
            "display": false
          },
          {
            "label": "Window Size",
            "name": "llmMemoryWindowSize",
            "type": "number",
            "default": "20",
            "description": "Uses a fixed window size to surface the last N messages",
            "show": {
              "llmMemoryType": "windowSize"
            },
            "id": "llmAgentflow_2-input-llmMemoryWindowSize-number",
            "display": false
          },
          {
            "label": "Max Token Limit",
            "name": "llmMemoryMaxTokenLimit",
            "type": "number",
            "default": "2000",
            "description": "Summarize conversations once token limit is reached. Default to 2000",
            "show": {
              "llmMemoryType": "conversationSummaryBuffer"
            },
            "id": "llmAgentflow_2-input-llmMemoryMaxTokenLimit-number",
            "display": false
          },
          {
            "label": "Input Message",
            "name": "llmUserMessage",
            "type": "string",
            "description": "Add an input message as user message at the end of the conversation",
            "rows": 4,
            "optional": true,
            "acceptVariable": true,
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_2-input-llmUserMessage-string",
            "display": false
          },
          {
            "label": "Return Response As",
            "name": "llmReturnResponseAs",
            "type": "options",
            "options": [
              {
                "label": "User Message",
                "name": "userMessage"
              },
              {
                "label": "Assistant Message",
                "name": "assistantMessage"
              }
            ],
            "default": "userMessage",
            "id": "llmAgentflow_2-input-llmReturnResponseAs-options",
            "display": true
          },
          {
            "label": "JSON Structured Output",
            "name": "llmStructuredOutput",
            "description": "Instruct the LLM to give output in a JSON structured schema",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "string"
              },
              {
                "label": "Type",
                "name": "type",
                "type": "options",
                "options": [
                  {
                    "label": "String",
                    "name": "string"
                  },
                  {
                    "label": "String Array",
                    "name": "stringArray"
                  },
                  {
                    "label": "Number",
                    "name": "number"
                  },
                  {
                    "label": "Boolean",
                    "name": "boolean"
                  },
                  {
                    "label": "Enum",
                    "name": "enum"
                  },
                  {
                    "label": "JSON Array",
                    "name": "jsonArray"
                  }
                ]
              },
              {
                "label": "Enum Values",
                "name": "enumValues",
                "type": "string",
                "placeholder": "value1, value2, value3",
                "description": "Enum values. Separated by comma",
                "optional": true,
                "show": {
                  "llmStructuredOutput[$index].type": "enum"
                }
              },
              {
                "label": "JSON Schema",
                "name": "jsonSchema",
                "type": "code",
                "placeholder": "{\n    \"answer\": {\n        \"type\": \"string\",\n        \"description\": \"Value of the answer\"\n    },\n    \"reason\": {\n        \"type\": \"string\",\n        \"description\": \"Reason for the answer\"\n    },\n    \"optional\": {\n        \"type\": \"boolean\"\n    },\n    \"count\": {\n        \"type\": \"number\"\n    },\n    \"children\": {\n        \"type\": \"array\",\n        \"items\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"value\": {\n                    \"type\": \"string\",\n                    \"description\": \"Value of the children's answer\"\n                }\n            }\n        }\n    }\n}",
                "description": "JSON schema for the structured output",
                "optional": true,
                "hideCodeExecute": true,
                "show": {
                  "llmStructuredOutput[$index].type": "jsonArray"
                }
              },
              {
                "label": "Description",
                "name": "description",
                "type": "string",
                "placeholder": "Description of the key"
              }
            ],
            "id": "llmAgentflow_2-input-llmStructuredOutput-array",
            "display": true
          },
          {
            "label": "Update Flow State",
            "name": "llmUpdateState",
            "description": "Update runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "asyncOptions",
                "loadMethod": "listRuntimeStateKeys"
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "acceptVariable": true,
                "acceptNodeOutputAsVariable": true
              }
            ],
            "id": "llmAgentflow_2-input-llmUpdateState-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "llmModel": "chatOpenAI",
          "llmMessages": [
            {
              "role": "system",
              "content": "<p>If {{conditionAgentflow_0}} equals \"Product Update\", analyse the email body found in {{question}} and write a summary in story format.</p><p>Ensure you carefully examine the content of the email, understand the main points, and then retell these as a concise narrative.</p><h1>Steps</h1><ul><li><p>Check if {{conditionAgentflow_0}} equals \"Product Update\".</p></li><li><p>Read and understand the email body in {{question}}.</p></li><li><p>Reflect on the key updates, reasons for changes, and their impact.</p></li><li><p>Organize your thoughts on the significance and context before summarizing.</p></li><li><p>Compose a brief summary using a story structure, clearly illustrating the flow of events or developments.</p></li><li><p>Only present your story summary after your reasoning is complete.</p></li></ul><h1>Output Format</h1><p>The output should be a single well-structured paragraph, written in a story format, retelling the product update as a short narrative. The story should highlight the who, what, why, and how, keeping the summary concise and coherent.</p><h1>Examples</h1><p><strong>Example 1</strong><br>Input:<br>{{conditionAgentflow_0}}: \"Product Update\"<br>{{question}}: \"Dear team, we're excited to announce version 2.0 of our application. Based on user feedback, we've introduced a streamlined interface and enhanced security features\"</p><p>Output:</p><p>What up Noble, Here's a new Product update for you!<br>Once upon a time, the product team listened to feedback from their users and realised that the application could be improved. They worked tirelessly, eventually unveiling version 2.0, featuring a sleeker interface and stronger security, delighting their user community.</p><p>(<strong>In real tasks, summaries may vary in length depending on content; use 3-6 sentences for most updates.</strong>)</p><h1>Notes</h1><ul><li><p>Only proceed if {{conditionAgentflow_0}} equals \"Product Update\".</p></li><li><p>Output must be in story (narrative) format.</p></li><li><p>Always reason about the content before writing the story.</p></li><li><p>Respond in the same language as the task.</p></li><li><p>Do not mention the sender at the end of the summary. It will be in the product story summary</p></li><li><p>Do not include any code blocks or extra formatting beyond what is described here.</p></li><li><p>Do not output anything else!</p></li><li><p>Always start the summary with \"What up Noble, Here's a new Product update for you!\"</p></li></ul>"
            }
          ],
          "llmEnableMemory": false,
          "llmReturnResponseAs": "userMessage",
          "llmStructuredOutput": "",
          "llmUpdateState": "",
          "llmModelConfig": {
            "cache": "",
            "modelName": "gpt-4.1",
            "temperature": "0.8",
            "streaming": false,
            "maxTokens": "1000",
            "topP": "",
            "frequencyPenalty": "",
            "presencePenalty": "",
            "timeout": "",
            "strictToolCalling": "",
            "stopSequence": "",
            "basepath": "",
            "proxyUrl": "",
            "baseOptions": "",
            "allowImageUploads": "",
            "reasoning": "",
            "llmModel": "chatOpenAI"
          }
        },
        "outputAnchors": [
          {
            "id": "llmAgentflow_2-output-llmAgentflow",
            "label": "LLM",
            "name": "llmAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "type": "agentFlow",
      "width": 148,
      "height": 72,
      "selected": false,
      "positionAbsolute": {
        "x": 636.0334980083603,
        "y": -309.26172566601434
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "startAgentflow_0",
      "sourceHandle": "startAgentflow_0-output-startAgentflow",
      "target": "customFunctionAgentflow_0",
      "targetHandle": "customFunctionAgentflow_0",
      "data": {
        "sourceColor": "#7EE787",
        "targetColor": "#E4B7FF",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "startAgentflow_0-startAgentflow_0-output-startAgentflow-customFunctionAgentflow_0-customFunctionAgentflow_0"
    },
    {
      "source": "customFunctionAgentflow_0",
      "sourceHandle": "customFunctionAgentflow_0-output-customFunctionAgentflow",
      "target": "agentAgentflow_0",
      "targetHandle": "agentAgentflow_0",
      "data": {
        "sourceColor": "#E4B7FF",
        "targetColor": "#4DD0E1",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "customFunctionAgentflow_0-customFunctionAgentflow_0-output-customFunctionAgentflow-agentAgentflow_0-agentAgentflow_0"
    },
    {
      "source": "conditionAgentflow_0",
      "sourceHandle": "conditionAgentflow_0-output-0",
      "target": "llmAgentflow_0",
      "targetHandle": "llmAgentflow_0",
      "data": {
        "sourceColor": "#FFB938",
        "targetColor": "#64B5F6",
        "edgeLabel": "0",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "conditionAgentflow_0-conditionAgentflow_0-output-0-llmAgentflow_0-llmAgentflow_0"
    },
    {
      "source": "conditionAgentflow_0",
      "sourceHandle": "conditionAgentflow_0-output-1",
      "target": "llmAgentflow_1",
      "targetHandle": "llmAgentflow_1",
      "data": {
        "sourceColor": "#FFB938",
        "targetColor": "#64B5F6",
        "edgeLabel": "1",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "conditionAgentflow_0-conditionAgentflow_0-output-1-llmAgentflow_1-llmAgentflow_1"
    },
    {
      "source": "conditionAgentflow_0",
      "sourceHandle": "conditionAgentflow_0-output-2",
      "target": "llmAgentflow_2",
      "targetHandle": "llmAgentflow_2",
      "data": {
        "sourceColor": "#FFB938",
        "targetColor": "#64B5F6",
        "edgeLabel": "2",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "conditionAgentflow_0-conditionAgentflow_0-output-2-llmAgentflow_2-llmAgentflow_2"
    },
    {
      "source": "agentAgentflow_0",
      "sourceHandle": "agentAgentflow_0-output-agentAgentflow",
      "target": "conditionAgentflow_0",
      "targetHandle": "conditionAgentflow_0",
      "data": {
        "sourceColor": "#4DD0E1",
        "targetColor": "#FFB938",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "agentAgentflow_0-agentAgentflow_0-output-agentAgentflow-conditionAgentflow_0-conditionAgentflow_0"
    }
  ]
}